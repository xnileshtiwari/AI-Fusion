{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XKf1whNlpykK",
        "01R02XojV56i",
        "_E1kn2aYWQRX",
        "4FVtpppnWyPL",
        "ov-M27CrZSpP",
        "Uni9XkxaXQzi"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xnileshtiwari/AI-Fusion/blob/main/Descript_like_wordhighlights_subtitles/Descript_like_wordhighlights_subtitles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code and files for this notebook: https://github.com/ramsrigouthamg/Supertranslate.ai/tree/main/Descript_like_wordhighlights_subtitles\n",
        "\n",
        "Author: [Ramsri Goutham](https://twitter.com/ramsri_goutham)"
      ],
      "metadata": {
        "id": "CCjyk1zgGeFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet ipython-autotime"
      ],
      "metadata": {
        "id": "tKs_aVFjb1iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "DxDG58qJc6sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1: Download video or upload the video in mp4 format that you want to convert to fancy word-level subtitles (audiogram)"
      ],
      "metadata": {
        "id": "XKf1whNlpykK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GCbvWXzXeUv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "mp4videoURL = \"https://github.com/ramsrigouthamg/Supertranslate.ai/raw/main/Descript_like_wordhighlights_subtitles/Intro.mp4\"\n",
        "videofilename = mp4videoURL.split('/')[-1]\n",
        "print (videofilename)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(mp4videoURL, videofilename)"
      ],
      "metadata": {
        "id": "HpTtfXWmYnIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2: Extract audio (mp3) from the video file"
      ],
      "metadata": {
        "id": "01R02XojV56i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python==0.2.0"
      ],
      "metadata": {
        "id": "kamWr_5paBJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "audiofilename = videofilename.replace(\".mp4\",'.mp3')\n",
        "\n",
        "# Create the ffmpeg input stream\n",
        "input_stream = ffmpeg.input(videofilename)\n",
        "\n",
        "# Extract the audio stream from the input stream\n",
        "audio = input_stream.audio\n",
        "\n",
        "# Save the audio stream as an MP3 file\n",
        "output_stream = ffmpeg.output(audio, audiofilename)\n",
        "\n",
        "# Overwrite output file if it already exists\n",
        "output_stream = ffmpeg.overwrite_output(output_stream)\n",
        "\n",
        "ffmpeg.run(output_stream)\n",
        "\n",
        "print (audiofilename)\n"
      ],
      "metadata": {
        "id": "1KYai-y0aT0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(audiofilename)\n"
      ],
      "metadata": {
        "id": "hyc89jXya7F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3: Get word-level transcription (speech-to-text) from audio using OpenAI's Whisper"
      ],
      "metadata": {
        "id": "_E1kn2aYWQRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git@248b6cb124225dd263bb9bd32d060b6517e067f8"
      ],
      "metadata": {
        "id": "xWFHdNEtbGeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "                                          #might take some time (approx 3- 5min depending on audio length)\n",
        "model = whisper.load_model(\"medium\")\n",
        "result = model.transcribe(audiofilename,word_timestamps=True)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "5gr8lCPybp3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total text\n",
        "print (result['text'])"
      ],
      "metadata": {
        "id": "tHSS7A4ec8ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# each subtitle segment\n",
        "for each in result['segments']:\n",
        "  print (each)"
      ],
      "metadata": {
        "id": "THnLUVO1dkqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordlevel_info = []\n",
        "\n",
        "for each in result['segments']:\n",
        "  words = each['words']\n",
        "  for word in words:\n",
        "    # print (word['word'], \"  \",word['start'],\" - \",word['end'])\n",
        "    wordlevel_info.append({'word':word['word'].strip(),'start':word['start'],'end':word['end']})\n"
      ],
      "metadata": {
        "id": "kHaUPOH1eIZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordlevel_info"
      ],
      "metadata": {
        "id": "kHostLbAfaO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step4: Store word-level timestamps into JSON file"
      ],
      "metadata": {
        "id": "4FVtpppnWyPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('data.json', 'w') as f:\n",
        "    json.dump(wordlevel_info, f,indent=4)"
      ],
      "metadata": {
        "id": "yvIVz0oTkdRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step5: Correct and save JSON file if there are transcription errors or if you need to merge any words into phrases. Load the new edited JSON file with new word-level timestamps"
      ],
      "metadata": {
        "id": "ov-M27CrZSpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('data.json', 'r') as f:\n",
        "    wordlevel_info_modified = json.load(f)\n"
      ],
      "metadata": {
        "id": "Q19dFuXkn6VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordlevel_info_modified"
      ],
      "metadata": {
        "id": "5gvj3OdfoLEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step6: Convert word-level timestamps JSON to line-level timestamps JSON. We want to display one line at a time and highlight words in it as they are spoken so we do this transformation."
      ],
      "metadata": {
        "id": "Uni9XkxaXQzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_into_lines(data):\n",
        "\n",
        "    MaxChars = 80\n",
        "    #maxduration in seconds\n",
        "    MaxDuration = 3.0\n",
        "    #Split if nothing is spoken (gap) for these many seconds\n",
        "    MaxGap = 1.5\n",
        "\n",
        "    subtitles = []\n",
        "    line = []\n",
        "    line_duration = 0\n",
        "    line_chars = 0\n",
        "\n",
        "\n",
        "    for idx,word_data in enumerate(data):\n",
        "        word = word_data[\"word\"]\n",
        "        start = word_data[\"start\"]\n",
        "        end = word_data[\"end\"]\n",
        "\n",
        "        line.append(word_data)\n",
        "        line_duration += end - start\n",
        "\n",
        "        temp = \" \".join(item[\"word\"] for item in line)\n",
        "\n",
        "\n",
        "        # Check if adding a new word exceeds the maximum character count or duration\n",
        "        new_line_chars = len(temp)\n",
        "\n",
        "        duration_exceeded = line_duration > MaxDuration\n",
        "        chars_exceeded = new_line_chars > MaxChars\n",
        "        if idx>0:\n",
        "          gap = word_data['start'] - data[idx-1]['end']\n",
        "          # print (word,start,end,gap)\n",
        "          maxgap_exceeded = gap > MaxGap\n",
        "        else:\n",
        "          maxgap_exceeded = False\n",
        "\n",
        "\n",
        "        if duration_exceeded or chars_exceeded or maxgap_exceeded:\n",
        "            if line:\n",
        "                subtitle_line = {\n",
        "                    \"word\": \" \".join(item[\"word\"] for item in line),\n",
        "                    \"start\": line[0][\"start\"],\n",
        "                    \"end\": line[-1][\"end\"],\n",
        "                    \"textcontents\": line\n",
        "                }\n",
        "                subtitles.append(subtitle_line)\n",
        "                line = []\n",
        "                line_duration = 0\n",
        "                line_chars = 0\n",
        "\n",
        "\n",
        "    if line:\n",
        "        subtitle_line = {\n",
        "            \"word\": \" \".join(item[\"word\"] for item in line),\n",
        "            \"start\": line[0][\"start\"],\n",
        "            \"end\": line[-1][\"end\"],\n",
        "            \"textcontents\": line\n",
        "        }\n",
        "        subtitles.append(subtitle_line)\n",
        "\n",
        "    return subtitles"
      ],
      "metadata": {
        "id": "y0aSTtzApekX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linelevel_subtitles = split_text_into_lines(wordlevel_info_modified)\n",
        "print (linelevel_subtitles)"
      ],
      "metadata": {
        "id": "GUvxaeTdtXpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in linelevel_subtitles:\n",
        "  json_str = json.dumps(line, indent=4)\n",
        "  print(json_str)"
      ],
      "metadata": {
        "id": "W3HG0zHhu9vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step7: Use Moviepy to create an audiogram with word-level highlights as they are spoken"
      ],
      "metadata": {
        "id": "vCymtgRfXlHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy==2.0.0.dev2\n",
        "!pip install imageio==2.25.1"
      ],
      "metadata": {
        "id": "0M04nc-UkVQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install imagemagick"
      ],
      "metadata": {
        "id": "olhtrcx0k0W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml"
      ],
      "metadata": {
        "id": "P44vCYP4k4Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import TextClip, CompositeVideoClip, ColorClip\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_caption(textJSON, framesize,font = \"Helvetica-Bold\",fontsize=80, color='white', bgcolor='blue'):\n",
        "    wordcount = len(textJSON['textcontents'])\n",
        "    full_duration = textJSON['end']-textJSON['start']\n",
        "\n",
        "    word_clips = []\n",
        "    xy_textclips_positions =[]\n",
        "\n",
        "    x_pos = 0\n",
        "    y_pos = 0\n",
        "    # max_height = 0\n",
        "    frame_width = framesize[0]\n",
        "    frame_height = framesize[1]\n",
        "    x_buffer = frame_width*1/10\n",
        "    y_buffer = frame_height*1/5\n",
        "\n",
        "    space_width = \"\"\n",
        "    space_height = \"\"\n",
        "\n",
        "    for index,wordJSON in enumerate(textJSON['textcontents']):\n",
        "      duration = wordJSON['end']-wordJSON['start']\n",
        "      word_clip = TextClip(wordJSON['word'], font = font,fontsize=fontsize, color=color).set_start(textJSON['start']).set_duration(full_duration)\n",
        "      word_clip_space = TextClip(\" \", font = font,fontsize=fontsize, color=color).set_start(textJSON['start']).set_duration(full_duration)\n",
        "      word_width, word_height = word_clip.size\n",
        "      space_width,space_height = word_clip_space.size\n",
        "      if x_pos + word_width+ space_width > frame_width-2*x_buffer:\n",
        "            # Move to the next line\n",
        "            x_pos = 0\n",
        "            y_pos = y_pos+ word_height+40\n",
        "\n",
        "            # Store info of each word_clip created\n",
        "            xy_textclips_positions.append({\n",
        "                \"x_pos\":x_pos+x_buffer,\n",
        "                \"y_pos\": y_pos+y_buffer,\n",
        "                \"width\" : word_width,\n",
        "                \"height\" : word_height,\n",
        "                \"word\": wordJSON['word'],\n",
        "                \"start\": wordJSON['start'],\n",
        "                \"end\": wordJSON['end'],\n",
        "                \"duration\": duration\n",
        "            })\n",
        "\n",
        "            word_clip = word_clip.set_position((x_pos+x_buffer, y_pos+y_buffer))\n",
        "            word_clip_space = word_clip_space.set_position((x_pos+ word_width +x_buffer, y_pos+y_buffer))\n",
        "            x_pos = word_width + space_width\n",
        "      else:\n",
        "            # Store info of each word_clip created\n",
        "            xy_textclips_positions.append({\n",
        "                \"x_pos\":x_pos+x_buffer,\n",
        "                \"y_pos\": y_pos+y_buffer,\n",
        "                \"width\" : word_width,\n",
        "                \"height\" : word_height,\n",
        "                \"word\": wordJSON['word'],\n",
        "                \"start\": wordJSON['start'],\n",
        "                \"end\": wordJSON['end'],\n",
        "                \"duration\": duration\n",
        "            })\n",
        "\n",
        "            word_clip = word_clip.set_position((x_pos+x_buffer, y_pos+y_buffer))\n",
        "            word_clip_space = word_clip_space.set_position((x_pos+ word_width+ x_buffer, y_pos+y_buffer))\n",
        "\n",
        "            x_pos = x_pos + word_width+ space_width\n",
        "\n",
        "\n",
        "      word_clips.append(word_clip)\n",
        "      word_clips.append(word_clip_space)\n",
        "\n",
        "\n",
        "    for highlight_word in xy_textclips_positions:\n",
        "\n",
        "      word_clip_highlight = TextClip(highlight_word['word'], font = font,fontsize=fontsize, color=color,bg_color = bgcolor).set_start(highlight_word['start']).set_duration(highlight_word['duration'])\n",
        "      word_clip_highlight = word_clip_highlight.set_position((highlight_word['x_pos'], highlight_word['y_pos']))\n",
        "      word_clips.append(word_clip_highlight)\n",
        "\n",
        "    return word_clips\n",
        "\n"
      ],
      "metadata": {
        "id": "YsBTKCm4lGFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from moviepy.editor import TextClip, CompositeVideoClip, concatenate_videoclips,VideoFileClip, ColorClip\n",
        "frame_size = (1080,1080)\n",
        "\n",
        "all_linelevel_splits=[]\n",
        "\n",
        "for line in linelevel_subtitles:\n",
        "  out = create_caption(line,frame_size)\n",
        "  all_linelevel_splits.extend(out)\n",
        "\n",
        "\n",
        "# Load the input video\n",
        "input_video = VideoFileClip(videofilename)\n",
        "# Get the duration of the input video\n",
        "input_video_duration = input_video.duration\n",
        "# Create a color clip with the given frame size, color, and duration\n",
        "background_clip = ColorClip(size=frame_size, color=(0, 0, 0)).set_duration(input_video_duration)\n",
        "\n",
        "# If you want to overlay this on the original video uncomment this and also change frame_size, font size and color accordingly.\n",
        "# final_video = CompositeVideoClip([input_video] + all_linelevel_splits)\n",
        "\n",
        "final_video = CompositeVideoClip([background_clip] + all_linelevel_splits)\n",
        "\n",
        "# Set the audio of the final video to be the same as the input video\n",
        "final_video = final_video.set_audio(input_video.audio)\n",
        "\n",
        "# Save the final clip as a video file with the audio included\n",
        "final_video.write_videofile(\"output.mp4\", fps=24, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jJojCQNpod7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step8: Visualize the final Descript like audiogram video"
      ],
      "metadata": {
        "id": "gos0diSTYAX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open(\"output.mp4\",'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "metadata": {
        "id": "Em5Cp-XEowrt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}